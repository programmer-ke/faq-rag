# generated by Brave Search

import streamlit as st
from openai import OpenAI

# Initialize app title and session state
st.title("LLM Chat App")
st.session_state.messages = []

client = OpenAI(
    base_url="http://localhost:11434/v1/",
    api_key="ollama"
)


# Define LLM response generation function
def generate_response(prompt):
    response = client.chat.completions.create(
        model="qwen2:0.5b",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# Create text input box for user input
prompt = st.chat_input("Enter your message:")

# Generate LLM response and display in chat message container
if prompt:
    response = generate_response(prompt)
    with st.chat_message("assistant"):
        st.markdown(response)
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
